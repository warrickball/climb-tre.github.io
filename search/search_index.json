{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CLIMB-TRE","text":"<p>The CLIMB Trusted Research Environment (CLIMB-TRE) project provides tools with which users can upload metagenomics data, with metadata, and analyse them on CLIMB.</p> <p>This site documents how to use the CLIMB-TRE tools and is distinct from more general documentation on using CLIMB. Read further for general information on how to upload or analyse data.</p> <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"analyse/","title":"Analysing data","text":""},{"location":"analyse/#overview","title":"Overview","text":"<p>Once data and metadata have been ingested into the Onyx database, you can query it using the Onyx client, which provides a command line interface (CLI) and Python API.  This short example demonstrates a few principal functions.  More are described in the <code>onyx-client</code> documentation.</p> <p>This guide also assumes that you're using a Notebook Server on CLIMB, so that once installed, the Onyx client will automatically be configured.</p>"},{"location":"analyse/#onyx-client-basics","title":"Onyx client basics","text":"<p>First, let's install the Onyx client, which is available through the conda-forge package <code>climb-onyx-client</code> and can thus be installed with <code>conda</code>.  As advised in the CLIMB docs on installing software, you should install the client in a new Conda environment. I'll name my environment <code>onyx</code> and install <code>climb-onyx-client</code>, as well as <code>ipykernel</code> (so that the client is available in my Jupyter Notebooks). <pre><code>jovyan:~$ conda create -n onyx ipykernel climb-onyx-client\n</code></pre> Let's activate this environment. <pre><code>jovyan:~$ conda activate onyx\n</code></pre> On Bryn's Notebook Servers, the client will automatically be configured. Try running the command-line client with <pre><code>(onyx) jovyan:~$ onyx\n</code></pre> This should show you some options and commands that are available. Have a look at your own profile with <pre><code>(onyx) jovyan:~$ onyx profile\n</code></pre> and which projects you have access to with <pre><code>(onyx) jovyan:~$ onyx projects\n</code></pre> You should see <code>mscape</code> listed.</p>"},{"location":"analyse/#querying-data","title":"Querying data","text":"<p>As an example task, we'll see if we can find any sequencing data performed for ZymoBIOMICS sources.  These are designed with  a particular specification of DNA from eight bacteria and two yeasts.  We can use these to see if our protocol correctly recovers the DNA fractions. I.e. if our protocol is biased.</p> <p>From the command line, the main route to querying Onyx is via the <code>filter</code> command. On its own, this queries the database with no filters.  The command <pre><code>(onyx) jovyan:~$ onyx filter mscape\n</code></pre> will produce tens of thousands of lines of JSON, so let's not do that just yet.  To first see which fields are available in the database, we can use <pre><code>(onyx) jovyan:~$ onyx fields mscape\n...\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 extraction_enrichment_protocol \u2502 optional \u2502 text              \u2502 Details of nucleic acid extraction and optional enrichment steps.            \u2502                                                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n...\n</code></pre> Let's search the database for entries with <code>zymo</code> (case-insensitive) in this field. <pre><code>(onyx) jovyan:~$ onyx filter mscape --field extraction_enrichment_protocol.icontains=zymo\n...\n</code></pre> That should return JSON data for a few entries.  You may wish to format the data as CSV or TSV with <code>--format csv</code> or <code>--format tsv</code>, respectively.</p>"},{"location":"analyse/#inspecting-some-pipeline-output-on-the-command-line","title":"Inspecting some pipeline output on the command line","text":"<p>When data is ingested into Onyx, a taxonomic classification is automatically run. The last part of the JSON data is usually some of this, in JSON format. The complete reports can be found in the S3 buckets given in the <code>'taxon_report'</code> field.  You can find this in the output you've already produced or modify the <code>filter</code> command to only request them using the <code>--include</code> flag. e.g. <pre><code>(onyx) jovyan:~$ onyx filter mscape --field extraction_enrichment_protocol.icontains=zymo --include=taxon_reports\n[\n    {\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-FDE50853AD/\"\n    },\n    {\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-04F4495068/\"\n    }\n]\n</code></pre> Multiple fields can be requested with the <code>--include</code> flag e.g. <pre><code>(onyx) jovyan:~$ onyx filter mscape --field extraction_enrichment_protocol.icontains=zymo --include climb_id,taxon_reports\n[\n    {\n        \"climb_id\": \"C-FDE50853AD\",\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-FDE50853AD/\"\n    },\n    {\n        \"climb_id\": \"C-04F4495068\",\n        \"taxon_reports\": \"s3://mscape-published-taxon-reports/C-04F4495068/\"\n    }\n]\n</code></pre> You can conversely exclude individual fields using the <code>--exclude</code> flag in the same way.</p> <p>Either way, you now have the location of the taxonomy reports.  Let's have a look with <code>s3cmd</code>. <pre><code>(onyx) jovyan:~$ s3cmd ls s3://mscape-published-taxon-reports/C-FDE50853AD/\n2023-11-10 12:56   146K  s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken.json\n2023-11-10 12:56     2G  s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_assignments.tsv\n2023-11-10 12:56   193K  s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_report.txt\n</code></pre> The plain text report is what we're after, so let's download that with <code>s3cmd</code>: <pre><code>(onyx) jovyan:~$ s3cmd get s3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_report.txt\ndownload: 's3://mscape-published-taxon-reports/C-FDE50853AD/PlusPF.kraken_report.txt' -&gt; './PlusPF.kraken_report.txt'  [1 of 1]\n 197750 of 197750   100% in    0s     3.79 MB/s  done\n</code></pre></p> <p>If you've never seen one of these reports before, it's worth having a quick look with a tool like <code>less</code> or by opening it using the JupyterLab file browser.  For reference, it's worth showing the header <pre><code>(onyx) jovyan:~$ head -n 1 PlusPF.kraken_report.txt\n% of Seqs       Clades  Taxonomies      Rank    Taxonomy ID     Scientific Name\n</code></pre> The Zymo sample is prepared with 12% Bacillus subtilis.  Let's see how much was actually reported in the results: <pre><code>(onyx) jovyan:~$ grep \"Bacillus subtilis\" PlusPF.kraken_report.txt\n 20.30  435278  1452    G1      653685                    Bacillus subtilis group\n  0.12  2624    1952    S       1423                        Bacillus subtilis\n  0.03  565     242     S1      135461                        Bacillus subtilis subsp. subtilis\n  0.01  108     108     S2      1404258                         Bacillus subtilis subsp. subtilis str. OH 131.1\n  ...\n</code></pre> Looks like 20.3%, though classified under Bacillus subtilis \"subgroup\", rather than Bacillus subtilis, which reportedly only comprises 0.12% of the sample. Most of that 20.3% is under Bacillus spizizenii.</p> <p>An important detail here is that the fraction reported in this output is not calculated in the same way as what's used in the reference values (12% for bacteria; 2% for yeasts). Let's make a fairer comparison using the JSON taxonomic data.</p>"},{"location":"analyse/#working-with-database-output-in-python","title":"Working with database output in Python","text":"<p>To fairly compare the taxonomic data with the reference values in the Zymo community, we need to know the proportions of gDNA, so we need to compute the number of base pairs that were assigned to each taxon. Let's make this comparison in Python using the Onyx client's Python API.</p> <p>Let's first run the same query for the Zymo data.  We'll follow the examples in the Onyx documentation and run the query in a context manager. <pre><code>import os\nfrom onyx import OnyxConfig, OnyxEnv, OnyxClient\n\nconfig = OnyxConfig(\n    domain=os.environ[OnyxEnv.DOMAIN],\n    token=os.environ[OnyxEnv.TOKEN],\n)\n\nwith OnyxClient(config) as client:\n    records = list(client.filter(\n        \"mscape\",\n        fields={\n            \"extraction_enrichment_protocol__icontains\": \"zymo\",\n        },\n    ))\n</code></pre> We've wrapped the <code>filter</code> call in a <code>list</code> because otherwise we get a generator.</p> <p>If you want to inspect the data, it's a bit easier to read if formatted with indentation, which can be done using the standard <code>json.dumps</code> function: <pre><code>import json\nprint(json.dumps(records[0], indent=2))  # show first record\n</code></pre> In each record, the <code>'taxa_files'</code> key gives us a list of dictionaries that each has a number of reads and a mean length, the product of which is the total number of base pairs that were read for that taxon.  A simple first step is to convert the taxonomic data (for the first record) into a Pandas DataFrame with <pre><code>import pandas as pd\n\ndf = pd.DataFrame(records[0]['taxa_files'])\n</code></pre> We also need to drop a few lower-level taxa that are already accounted for in higher ones. e.g. the reads for Bacillus spizizenii TU-B-10 are among the reads counted for Bacillus spizizenii.  A quick way of doing this is by selecting the rows that have only two words in their names. <pre><code>df = df.loc[df['human_readable'].apply(lambda name: len(name.split()) == 2)]\n</code></pre> Now, let's add columns for the total number of base pairs associated with each taxon and what proportion that is of the total. <pre><code>df['gDNA'] = df['n_reads']*df['mean_len']\ndf['proportion'] = df['gDNA']/df['gDNA'].sum()\n</code></pre> Finally, let's make a rough plot with a black dashed line at 12%. <pre><code>import matplotlib.pyplot as plt\n\nplt.plot(df['human_readable'], df['proportion']*100, 'o')\nplt.axhline(12, c='k', ls='--');\nplt.xticks(rotation=22.5, ha='right');\n</code></pre></p> <p></p> <p>There are some clear discrepancies\u2014Pseudomonas aeruginosa is underreported and Bacillus spizizenii is overreported\u2014but this matches results by e.g. Nicholls et al. (2019).</p> <p>This short example is intended as a basic demonstration of what's possible in CLIMB-TRE.  We're always interested to hear more examples of research questions that CLIMB-TRE can answer, so let us know if you have an example that could be included as a guide for others.</p> <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"common/","title":"Project specification structure","text":""},{"location":"common/#overview","title":"Overview","text":"<p>All projects on CLIMB-TRE are specified in the same way.</p>"},{"location":"common/#files-to-be-provided","title":"Files to be provided","text":"<p>These are the files that must be uploaded (usually some sequencing reads and a metadata file). Submissions without the correct number of files provided will be considered incomplete and will not be processed.</p>"},{"location":"common/#file-naming-convention","title":"File naming convention","text":"<p>This is the convention to which the provided file names must adhere.</p> <p>Each of the files to be provided will use the same basename followed by specified extensions (e.g. for data versus metadata).  The basename for each file is usually several fields separated by a fixed number of stops/periods (<code>.</code>).</p> <p>The set of valid characters is usually limited to letters, numbers, hyphens (<code>-</code>) and underscores (<code>_</code>) but this will be specified. Filenames containing forbidden characters or extensions will not be processed.</p>"},{"location":"common/#file-processing-requirements","title":"File processing requirements","text":""},{"location":"common/#fastq","title":"FASTQ","text":"<ul> <li>Must be gzipped.</li> <li>Must adhere to the FASTQ format.</li> </ul>"},{"location":"common/#csv","title":"CSV","text":"<ul> <li>Must be a plain text file with comma-delimited data.</li> <li>Must contain two rows: the first will contain the column names and the second will contain the data.</li> <li>Must have column names that match the specification exactly.</li> <li>Must not have missing data for required fields.</li> <li>Must not have invalid data (e.g. <code>\"N/A\"</code>) to circumvent missing data checks.</li> <li>Must not contain metadata that contradicts the file name.</li> <li>Must use the latest version of the metadata specification.</li> </ul>"},{"location":"common/#metadata-specification","title":"Metadata specification","text":"<p>The metadata for each project is specified in tables detailing required fields (which must not be empty) and optional fields (which can be left empty).</p>"},{"location":"common/#project-upload-buckets","title":"Project upload buckets","text":"<p>Files should be uploaded to S3 buckets hosted at the <code>s3.climb.ac.uk</code> endpoint. </p> <p>The bucket names are a combination of:</p> <ul> <li>Project (e.g. <code>mscape</code>).</li> <li>Site code (e.g. <code>bham</code>).</li> <li>Platform (e.g. <code>illumina</code>).</li> <li>A flag that indicates a test (<code>test</code>) or production (<code>prod</code>) submission.</li> </ul> <p>All files must be placed in the root directory of the submission buckets. Any S3 URI containing a directory will be ignored. Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"mscape-analysis/","title":"mSCAPE Analysis Specification","text":""},{"location":"mscape-analysis/#analysis-fields","title":"Analysis fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>climb_id</code> <code>text</code> Unique identifier for a project record in Onyx. <code>published_date</code> <code>date</code> The date the project record was published in Onyx. \u2022 Output format: <code>iso-8601</code> <code>site</code> <code>choice</code> The site or sequencing centre providing the data. \u2022 Choices: <code>bham</code>, <code>gstt</code>, <code>public</code>, <code>ukhsa</code> <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. <code>platform</code> <code>choice</code> The platform used to sequence the data. \u2022 Choices: <code>illumina</code>, <code>ont</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Choices: <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Choices: <code>water_extraction_control</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>none</code> <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Output format: <code>YYYY-MM-DD</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). <code>study_id</code> <code>choice</code> Used to identify study or if NHS residual sample. <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>GB</code>, <code>GB-ENG</code>, <code>GB-NIR</code>, <code>GB-SCT</code>, <code>GB-WLS</code> <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database. <code>ingest_report</code> <code>text</code> HTML report summarising the read profile and taxa identified. <code>taxon_reports</code> <code>text</code> Folder of all classification output files. <code>human_filtered_reads_1</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>human_filtered_reads_2</code> <code>text</code> Compressed FASTQ of input reads that have been filtered for human reads. <code>unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which could not be classified. <code>viral_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral. <code>viral_and_unclassified_reads_1</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>viral_and_unclassified_reads_2</code> <code>text</code> Compressed FASTQ of input reads which were classified as viral or were unclassified. <code>classifier</code> <code>choice</code> The classifier used. \u2022 Choices: <code>Kraken2</code> <code>classifier_version</code> <code>text</code> Version of the classifier used. <code>classifier_db</code> <code>choice</code> Database used for read classification. \u2022 Choices: <code>PlusPF</code> <code>classifier_db_date</code> <code>date</code> Date classifier database was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>ncbi_taxonomy_date</code> <code>date</code> Date that the NCBI taxonomy dump was produced. \u2022 Output format: <code>YYYY-MM-DD</code> <code>scylla_version</code> <code>text</code> Version of the scylla pipeline used. <code>taxa_files</code> <code>relation</code> Table of all species level taxa extracted. <code>taxa_files.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>taxa_files.human_readable</code> <code>text</code> A human readable name for the taxa. <code>taxa_files.n_reads</code> <code>integer</code> The number of reads extracted for the taxa. <code>taxa_files.avg_quality</code> <code>decimal</code> The mean quality of reads extracted for the taxa. <code>taxa_files.mean_len</code> <code>decimal</code> The mean length of reads extracted for the taxa. <code>taxa_files.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>taxa_files.fastq_1</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>taxa_files.fastq_2</code> <code>text</code> Compressed FASTQ of extracted reads for the taxa. <code>classifier_calls</code> <code>relation</code> Table summarising the NCBI taxonomy ids, counts and ranks of all taxa found by the classifier. <code>classifier_calls.taxon_id</code> <code>integer</code> The NCBI taxonomy id associated with the taxa. <code>classifier_calls.human_readable</code> <code>text</code> A human readable name for the taxa. <code>classifier_calls.percentage</code> <code>decimal</code> The percentage of the (dehumanised) sample that the taxa represents. <code>classifier_calls.count_descendants</code> <code>integer</code> The number of reads mapping to this taxa and all descendant taxa. <code>classifier_calls.count_direct</code> <code>integer</code> The number of reads mapping directly to the taxa. <code>classifier_calls.rank</code> <code>choice</code> The rank of the taxa. \u2022 Choices: <code>C</code>, <code>D</code>, <code>F</code>, <code>G</code>, <code>K</code>, <code>O</code>, <code>P</code>, <code>R</code>, <code>S</code>, <code>U</code> <code>classifier_calls.raw_rank</code> <code>text</code> The rank of the taxa including an intermediate grading. <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"mscape-examples/","title":"Analysis examples for mSCAPE","text":""},{"location":"mscape-examples/#retrieve-all-samples-that-contain-a-particular-taxa-eg-pseudomonas","title":"Retrieve all samples that contain a particular taxa e.g. <code>pseudomonas</code>","text":"<p>This can be done through the CLI:</p> <pre><code>$ onyx filter mscape --field taxa_files.human_readable.icontains=pseudomonas --format csv\n</code></pre> <p>Or through the Python API:</p> <pre><code>import os\nfrom onyx import OnyxConfig, OnyxClient, OnyxEnv, OnyxField\n\nconfig = OnyxConfig(\n    domain=os.environ[OnyxEnv.DOMAIN],\n    token=os.environ[OnyxEnv.TOKEN],\n)\n\nwith OnyxClient(config) as client:\n    # Filter for read sets containing \"pseudomonas\"\n    for metadata in client.query(\n        \"mscape\",\n        query=OnyxField(taxa_files__human_readable__icontains=\"pseudomonas\"),\n    ):\n        # Do analysis here\n        print(\"CLIMB ID:\", metadata[\"climb_id\"])\n        print(\"Published date:\", metadata[\"published_date\"])\n\n        # The query command by default does not return taxonomic information\n        # To get this, we have to call the `get` method and retrieve the samples individually\n        full_metadata = client.get(\"mscape\", metadata[\"climb_id\"])\n\n        # Now we can inspect the taxonomic information for the readset\n        print(\n            \"Number of binned reads:\", len(full_metadata[\"taxa_files\"])\n        )  # etc. Do more analysis\n        print(\"Pseudomonas taxa:\")\n        for taxa in full_metadata[\"taxa_files\"]:\n            if \"pseudomonas\" in taxa[\"human_readable\"].lower():\n                print(\"-\", taxa[\"human_readable\"])\n</code></pre> <p>Example output for this python script: <pre><code>CLIMB ID: C-FE89BACF2D\nPublished date: 2024-02-28\nNumber of binned reads: 3\nPseudomonas taxa:\n- Pseudomonas aeruginosa\n- Pseudomonas aeruginosa PA7\nCLIMB ID: C-470A57DCD0\nPublished date: 2024-02-28\nNumber of binned reads: 8\nPseudomonas taxa:\n- Pseudomonas aeruginosa\n- Pseudomonas aeruginosa PA7\nCLIMB ID: C-FB67513BE0\nPublished date: 2024-02-28\nNumber of binned reads: 4\nPseudomonas taxa:\n- Pseudomonas aeruginosa\nCLIMB ID: C-E49EED98E4\nPublished date: 2024-02-28\nNumber of binned reads: 3\nPseudomonas taxa:\n- Pseudomonas aeruginosa\n- Pseudomonas aeruginosa PA7\n...\n</code></pre></p>"},{"location":"mscape-examples/#get-a-csv-distribution-of-all-binned-taxa-present-in-the-dataset","title":"Get a CSV distribution of all binned taxa present in the dataset","text":"<p>Through the CLI:</p> <pre><code>$ onyx filter mscape --summarise taxa_files.taxon_id,taxa_files.human_readable --format csv\n</code></pre> <p>Or through the Python API:</p> <pre><code>import os\nfrom onyx import OnyxConfig, OnyxClient, OnyxEnv, OnyxField\n\nconfig = OnyxConfig(\n    domain=os.environ[OnyxEnv.DOMAIN],\n    token=os.environ[OnyxEnv.TOKEN],\n)\n\nwith OnyxClient(config) as client:\n    for summary_data in client.query(\n        \"mscape\",\n        summarise=[\"taxa_files__taxon_id\", \"taxa_files__human_readable\"],\n    ):\n        # Do analysis here\n        print(\"Taxon ID:\", summary_data[\"taxa_files__taxon_id\"])\n        print(\"Taxon name:\", summary_data[\"taxa_files__human_readable\"])\n        print(\"Number of readsets present:\", summary_data[\"count\"])\n</code></pre> <p>Example output for this python script:</p> <p><pre><code>Taxon ID: 1304\nTaxon name: Streptococcus salivarius\nNumber of readsets present: 22\nTaxon ID: 1305\nTaxon name: Streptococcus sanguinis\nNumber of readsets present: 9\nTaxon ID: 1313\nTaxon name: Streptococcus pneumoniae\nNumber of readsets present: 26\nTaxon ID: 1318\nTaxon name: Streptococcus parasanguinis\nNumber of readsets present: 42\nTaxon ID: 1328\nTaxon name: Streptococcus anginosus\nNumber of readsets present: 4\n...\n</code></pre> Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"mscape/","title":"mSCAPE Uploader Specification","text":""},{"location":"mscape/#files-to-be-provided","title":"Files to be provided","text":"<p>For paired-end Illumina sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ 1 file containing the forward sequencing reads.</li> <li>A FASTQ 2 file containing the reverse sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul> <p>For ONT sequencing data, suppliers must provide:</p> <ul> <li>A FASTQ file containing the sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul>"},{"location":"mscape/#file-naming-convention","title":"File naming convention","text":"<p>The base filenames should be of the form</p> <pre><code>mscape.[run_index].[run_id].[extension]\n</code></pre> <p>where:</p> <ul> <li><code>[run_index]</code> is an identifier that is unique within a sequencing run, e.g. a sequencing barcode identifier, or a 96-well plate co-ordinate.</li> <li><code>[run_id]</code> is the name of the sequencing run as given by the supplier's sequencing instrument (not an internal identifier assigned by the supplier).</li> <li><code>[extension]</code> is the file extension indicating the file type.</li> </ul>"},{"location":"mscape/#file-name-extensions","title":"File name extensions","text":"<p>For paired-end Illumina sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>1.fastq.gz</code> for the forward FASTQ file.</li> <li><code>2.fastq.gz</code> for the reverse FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul> <p>For ONT sequencing data, the extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>fastq.gz</code> for the forward FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul>"},{"location":"mscape/#valid-characters","title":"Valid characters","text":"<p>The <code>[run_index]</code>, <code>[run_id]</code> and <code>[extension]</code> must contain only:</p> <ul> <li>Letters (<code>A-Z</code>, <code>a-z</code>).</li> <li>Numbers (<code>0-9</code>).</li> <li>Hyphens (<code>-</code>).</li> <li>Underscores (<code>_</code>).</li> </ul>"},{"location":"mscape/#buckets","title":"Buckets","text":"<p>Bucket names follow the general convention:</p> <pre><code>mscape-[sequencing_org]-[platform]-[test_flag]\n</code></pre>"},{"location":"mscape/#metadata-specification","title":"Metadata specification","text":""},{"location":"mscape/#required-fields","title":"Required fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_id</code> <code>text</code> The sequencing provider's identifier for a sample. \u2022 Max length: <code>50</code> <code>run_index</code> <code>text</code> The sequencing provider's identifier for the position of a sample on a run. \u2022 Max length: <code>50</code> <code>run_id</code> <code>text</code> Unique identifier assigned to the run by the sequencing instrument. \u2022 Max length: <code>100</code> <code>input_type</code> <code>choice</code> The type of input sequenced. \u2022 Choices: <code>community_standard</code>, <code>negative_control</code>, <code>positive_control</code>, <code>specimen</code>, <code>validation_material</code> <code>sample_source</code> <code>choice</code> The source from which the sample was collected. \u2022 Choices: <code>blood</code>, <code>environment</code>, <code>faecal</code>, <code>lower_respiratory</code>, <code>nose_and_throat</code>, <code>other</code>, <code>plasma</code>, <code>stool</code>, <code>tissue</code>, <code>upper_respiratory</code>, <code>urine</code> <code>sample_type</code> <code>choice</code> The type of sampling method used. \u2022 Choices: <code>aspirate</code>, <code>bal</code>, <code>biopsy</code>, <code>other</code>, <code>sputum</code>, <code>swab</code> <code>spike_in</code> <code>choice</code> The type of spike-in used in the run. \u2022 Choices: <code>none</code> <p>At least one of the following fields are required:</p> Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>collection_date</code> <code>date</code> The date the sample was collected. \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code> <code>received_date</code> <code>date</code> The date the sample was received by the sequencing centre (if collection_date unavailable). \u2022 Input formats: <code>YYYY-MM</code>, <code>YYYY-MM-DD</code>\u2022 Output format: <code>YYYY-MM-DD</code>"},{"location":"mscape/#optional-fields","title":"Optional fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. \u2022 Max length: <code>50</code> <code>specimen_type_details</code> <code>choice</code> Named control or standard for specimens. \u2022 Required when <code>input_type</code> is: <code>specimen</code>\u2022 Choices: <code>respiratory_infection</code> <code>control_type_details</code> <code>choice</code> Named control or standard for positive and negative controls. \u2022 Required when <code>input_type</code> is: <code>positive_control</code>\u2022 Required when <code>input_type</code> is: <code>negative_control</code>\u2022 Choices: <code>water_extraction_control</code> <code>is_approximate_date</code> <code>bool</code> The date is approximate e.g. the sample is from a public repository and it is unclear whether the date corresponds to collection or publishing. \u2022 Default: <code>False</code> <code>batch_id</code> <code>text</code> Used to identify samples prepared in the same laboratory batch (e.g. extraction, library and/or sequencing). \u2022 Max length: <code>100</code> <code>study_id</code> <code>choice</code> Used to identify study or if NHS residual sample. <code>study_centre_id</code> <code>text</code> Used to identify sequencing centre. \u2022 Max length: <code>100</code> <code>sequence_purpose</code> <code>choice</code> Used to differentiate between clinical or research studies. \u2022 Choices: <code>clinical</code>, <code>research</code> <code>governance_status</code> <code>choice</code> Did the patient consent to their sample being used for research purposes or not. \u2022 Default: <code>no_consent_for_research</code>\u2022 Choices: <code>consented_for_research</code>, <code>no_consent_for_research</code>, <code>open</code> <code>iso_country</code> <code>choice</code> Country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>GB</code>, <code>GB-ENG</code>, <code>GB-NIR</code>, <code>GB-SCT</code>, <code>GB-WLS</code> <code>iso_region</code> <code>choice</code> Region that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Requires: <code>iso_country</code>\u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>extraction_enrichment_protocol</code> <code>text</code> Details of nucleic acid extraction and optional enrichment steps. <code>library_protocol</code> <code>text</code> Details of sequencing library construction. <code>sequencing_protocol</code> <code>text</code> Details of sequencing. <code>bioinformatics_protocol</code> <code>text</code> Detail of initial bioinformatics protocol, for example versions of basecalling software and models used, any read quality filtering/trimming employed. <code>dehumanisation_protocol</code> <code>text</code> Details of bioinformatics method used for human read removal. <code>is_public_dataset</code> <code>bool</code> The sample is from a public dataset. Please only set this after it has been made public. \u2022 Default: <code>False</code> <code>public_database_name</code> <code>choice</code> The public repository where the data is. \u2022 Choices: <code>ENA</code>, <code>SRA</code> <code>public_database_accession</code> <code>text</code> The accession for the data in the public database. <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"onyx_client_installation_guide/","title":"<code>onyx-client</code>","text":""},{"location":"onyx_client_installation_guide/#setup","title":"Setup","text":""},{"location":"onyx_client_installation_guide/#install-from-conda-forge","title":"Install from conda-forge","text":"<pre><code>$ conda create --name onyx --channel conda-forge climb-onyx-client\n</code></pre>"},{"location":"onyx_client_installation_guide/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>$ pip install climb-onyx-client\n</code></pre>"},{"location":"onyx_client_installation_guide/#build-from-source","title":"Build from source","text":"<p>Download and install the client into a Python virtual environment:</p> <pre><code>$ git clone https://github.com/CLIMB-COVID/onyx-client.git\n$ cd onyx-client/\n$ python -m venv .venv\n$ source .venv/bin/activate\n$ pip install .\n</code></pre> <p>Check it works:</p> <pre><code>$ onyx\n\n Usage: onyx [OPTIONS] COMMAND [ARGS]...\n\n API for pathogen metadata.\n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --domain    -d      TEXT  Domain name for connecting to Onyx. [env var: ONYX_DOMAIN]      \u2502\n\u2502                           [default: None]                                                 \u2502\n\u2502 --token     -t      TEXT  Token for authenticating with Onyx. [env var: ONYX_TOKEN]       \u2502\n\u2502                           [default: None]                                                 \u2502\n\u2502 --username  -u      TEXT  Username for authenticating with Onyx. [env var: ONYX_USERNAME] \u2502\n\u2502                           [default: None]                                                 \u2502\n\u2502 --password  -p      TEXT  Password for authenticating with Onyx. [env var: ONYX_PASSWORD] \u2502\n\u2502                           [default: None]                                                 \u2502\n\u2502 --version   -v            Show the client version number and exit.                        \u2502\n\u2502 --help      -h            Show this message and exit.                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 projects       View available projects.                                                   \u2502\n\u2502 fields         View the field specification for a project.                                \u2502\n\u2502 choices        View options for a choice field.                                           \u2502\n\u2502 get            Get a record from a project.                                               \u2502\n\u2502 filter         Filter multiple records from a project.                                    \u2502\n\u2502 identify       Get the anonymised identifier for a value on a field.                      \u2502\n\u2502 profile        View profile information.                                                  \u2502\n\u2502 siteusers      View users from the same site.                                             \u2502\n\u2502 auth           Authentication commands.                                                   \u2502\n\u2502 admin          Admin commands.                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>For more information, check out the documentation.</p> <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"pathsafe-analysis/","title":"PATH-SAFE Analysis Specification","text":""},{"location":"pathsafe-analysis/#analysis-fields","title":"Analysis fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>climb_id</code> <code>text</code> Unique identifier for a project record in Onyx. <code>published_date</code> <code>date</code> The date the project record was published in Onyx. \u2022 Output format: <code>iso-8601</code> <code>site</code> <code>choice</code> Laboratory, organisation or agency the sample has been submitted by. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>PHS</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>biosample_id</code> <code>text</code> The sequencing providers identifier for a sample. <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. <code>run_id</code> <code>text</code> The unique identifier assigned to the run by the sequencing instrument. <code>platform</code> <code>choice</code> The platform used to sequence the data. \u2022 Choices: <code>illumina</code> <code>sample_accession</code> <code>text</code> Sample accession number if sequence is publically available in SRA. <code>enterobase_barcode</code> <code>text</code> Sample barcode if sequence is publically available in EnteroBase. <code>collection_date</code> <code>date</code> Date of sample collection. \u2022 Output format: <code>YYYY-MM</code> <code>receipt_date</code> <code>date</code> Date of receipt of the sample. \u2022 Output format: <code>YYYY-MM</code> <code>month</code> <code>integer</code> Month of sample collected if available or month of receipt otherwise. <code>year</code> <code>integer</code> Year of sample collected if available or year of sample receipt otherwise. <code>sequence_org</code> <code>choice</code> Laboratory, organisation or agency the sample has been sequenced by. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>PHS</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>sequence_org_other</code> <code>text</code> Additional laboratory, organisation or agency the sample has been sequenced by. <code>data_steward</code> <code>choice</code> Laboratory, organisation or agency that hold the data for the sample. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>OTHER</code>, <code>PHS</code>, <code>PHW</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>data_steward_other</code> <code>text</code> Additional laboratory, organisation or agency that hold the data for the sample. <code>source_type</code> <code>choice</code> Source of the sample. \u2022 Choices: <code>animal</code>, <code>animal_associated_environment</code>, <code>environment</code>, <code>food</code>, <code>food_associated_environment</code>, <code>human</code>, <code>human_associated_environment</code>, <code>missing</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>other_environment</code>, <code>restricted_access</code> <code>country</code> <code>choice</code> The country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>GB</code>, <code>GB-ENG</code>, <code>GB-NIR</code>, <code>GB-SCT</code>, <code>GB-WLS</code> <code>county</code> <code>choice</code> County that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>sample_purpose</code> <code>choice</code> The purpose of the sample collection. \u2022 Choices: <code>active_surveillance</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>outbreak_initiated_surveillance</code>, <code>outbreak_investigation</code>, <code>population_based_surveillance</code>, <code>research</code>, <code>restricted_access</code>, <code>routine_diagnostics</code>, <code>routine_surveillance</code> <code>sample_purpose_other</code> <code>text</code> Additional purpose of the sample collection. <code>sequencing_kit</code> <code>text</code> The sequencing kit used. <code>library_kit</code> <code>text</code> The library kit used to prep the sample. <code>is_multiplexed</code> <code>bool</code> Whether the sample was multiplexed. <code>type_of_sample</code> <code>choice</code> Type of sample used to produce the sequence. \u2022 Choices: <code>genomic</code> <code>assembly</code> <code>text</code> <code>pathogenwatch_uuid</code> <code>text</code> <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"pathsafe/","title":"PATH-SAFE Uploader Specification","text":""},{"location":"pathsafe/#files-to-be-provided","title":"Files to be provided","text":"<ul> <li>A FASTQ 1 file containing the forward sequencing reads.</li> <li>A FASTQ 2 file containing the reverse sequencing reads.</li> <li>A CSV file containing the metadata associated with sequencing the sample.</li> </ul>"},{"location":"pathsafe/#file-naming-convention","title":"File naming convention","text":"<p>The base filenames should be of the form</p> <pre><code>pathsafe.[run_index].[run_id].[extension]\n</code></pre> <p>where:</p> <ul> <li><code>[run_index]</code> is an identifier that is unique within a sequencing run, e.g. a sequencing barcode identifier, or a 96-well plate co-ordinate.</li> <li><code>[run_id]</code> is the name of the sequencing run as given by the supplier's sequencing instrument (not an internal identifier assigned by the supplier).</li> <li><code>[extension]</code> is the file extension indicating the file type.</li> </ul>"},{"location":"pathsafe/#file-name-extensions","title":"File name extensions","text":"<p>The extensions (<code>[extension]</code>) should be:</p> <ul> <li><code>1.fastq.gz</code> for the forward FASTQ file.</li> <li><code>2.fastq.gz</code> for the reverse FASTQ file.</li> <li><code>csv</code> for the CSV metadata file.</li> </ul>"},{"location":"pathsafe/#valid-characters","title":"Valid characters","text":"<p>The <code>[run_index]</code>, <code>[run_id]</code> and <code>[extension]</code> must contain only:</p> <ul> <li>Letters (<code>A-Z</code>, <code>a-z</code>).</li> <li>Numbers (<code>0-9</code>).</li> <li>Hyphens (<code>-</code>).</li> <li>Underscores (<code>_</code>).</li> </ul>"},{"location":"pathsafe/#metadata-specification","title":"Metadata specification","text":""},{"location":"pathsafe/#required-fields","title":"Required fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_id</code> <code>text</code> The sequencing providers identifier for a sample. \u2022 Max length: <code>50</code> <code>run_index</code> <code>text</code> The sequencing provider's identifier for the position of a sample on a run. \u2022 Max length: <code>50</code> <code>run_id</code> <code>text</code> The unique identifier assigned to the run by the sequencing instrument. \u2022 Max length: <code>100</code> <code>year</code> <code>integer</code> Year of sample collected if available or year of sample receipt otherwise. <code>data_steward</code> <code>choice</code> Laboratory, organisation or agency that hold the data for the sample. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>OTHER</code>, <code>PHS</code>, <code>PHW</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>source_type</code> <code>choice</code> Source of the sample. \u2022 Choices: <code>animal</code>, <code>animal_associated_environment</code>, <code>environment</code>, <code>food</code>, <code>food_associated_environment</code>, <code>human</code>, <code>human_associated_environment</code>, <code>missing</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>other_environment</code>, <code>restricted_access</code> <code>country</code> <code>choice</code> The country that the sample was collected in, using ISO-3166-1 alpha-2 codes (https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes), unless within United Kingdom. If so, use ISO-3166-2:GB (https://en.wikipedia.org/wiki/ISO_3166-2:GB). \u2022 Choices: <code>GB</code>, <code>GB-ENG</code>, <code>GB-NIR</code>, <code>GB-SCT</code>, <code>GB-WLS</code> <code>sample_purpose</code> <code>choice</code> The purpose of the sample collection. \u2022 Choices: <code>active_surveillance</code>, <code>not_applicable</code>, <code>not_collected</code>, <code>not_provided</code>, <code>other</code>, <code>outbreak_initiated_surveillance</code>, <code>outbreak_investigation</code>, <code>population_based_surveillance</code>, <code>research</code>, <code>restricted_access</code>, <code>routine_diagnostics</code>, <code>routine_surveillance</code>"},{"location":"pathsafe/#optional-fields","title":"Optional fields","text":"Field\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Data type Description Restrictions <code>biosample_source_id</code> <code>text</code> Unique identifier for an individual to permit multiple samples from the same individual to be linked. \u2022 Max length: <code>50</code> <code>sample_accession</code> <code>text</code> Sample accession number if sequence is publically available in SRA. <code>enterobase_barcode</code> <code>text</code> Sample barcode if sequence is publically available in EnteroBase. <code>collection_date</code> <code>date</code> Date of sample collection. \u2022 Input formats: <code>YYYY-MM</code>\u2022 Output format: <code>YYYY-MM</code> <code>receipt_date</code> <code>date</code> Date of receipt of the sample. \u2022 Input formats: <code>YYYY-MM</code>\u2022 Output format: <code>YYYY-MM</code> <code>month</code> <code>integer</code> Month of sample collected if available or month of receipt otherwise. <code>sequence_org</code> <code>choice</code> Laboratory, organisation or agency the sample has been sequenced by. \u2022 Choices: <code>APHA</code>, <code>FSA</code>, <code>FSS</code>, <code>PHS</code>, <code>SSSCDRL</code>, <code>UKHSA</code> <code>sequence_org_other</code> <code>text</code> Additional laboratory, organisation or agency the sample has been sequenced by. \u2022 Requires: <code>sequence_org</code> <code>data_steward_other</code> <code>text</code> Additional laboratory, organisation or agency that hold the data for the sample. \u2022 Required when <code>data_steward</code> is: <code>OTHER</code> <code>county</code> <code>choice</code> County that the sample was collected in, using the second level subdivision codes of ISO-3166-2:GB (https://www.iso.org/obp/ui/#iso:code:3166:GB). \u2022 Requires: <code>country</code>\u2022 Choices: <code>GB-ABC</code>, <code>GB-ABD</code>, <code>GB-ABE</code>, <code>GB-AGB</code>, <code>GB-AGY</code>, <code>GB-AND</code>, <code>GB-ANN</code>, <code>GB-ANS</code>, <code>GB-BAS</code>, <code>GB-BBD</code>, <code>GB-BCP</code>, <code>GB-BDF</code>, <code>GB-BDG</code>, <code>GB-BEN</code>, <code>GB-BEX</code>, <code>GB-BFS</code>, <code>GB-BGE</code>, <code>GB-BGW</code>, <code>GB-BIR</code>, <code>GB-BKM</code>, ... <code>sample_purpose_other</code> <code>text</code> Additional purpose of the sample collection. \u2022 Required when <code>sample_purpose</code> is: <code>other</code> <code>sequencing_kit</code> <code>text</code> The sequencing kit used. <code>library_kit</code> <code>text</code> The library kit used to prep the sample. <code>is_multiplexed</code> <code>bool</code> Whether the sample was multiplexed. <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"},{"location":"upload/","title":"Uploading data","text":""},{"location":"upload/#overview","title":"Overview","text":"<p>Data in CLIMB-TRE is managed through a database called Onyx. To upload data into Onyx, you must deposit the appropriate files (including the metadata) into the relevant S3 bucket on CLIMB. We recommend doing this using the AWS or <code>s3cmd</code> command-line tools. For general information about how to upload data to CLIMB, see the CLIMB docs on setting up <code>s3cmd</code> locally and running <code>s3cmd</code> locally or on Bryn. You may also wish to review the overall CLIMB storage documentation.</p> <p>Each CLIMB-TRE project requires data (e.g. FASTQ sequencing reads) and metadata (e.g. a CSV file).  These must match the relevant specification (\"spec\") and be uploaded to the appropriate S3 bucket.  Doing so will trigger the ingest process.  Data that doesn't meet the spec will not be ingested.</p> <p>Lines starting with <code>$</code> indicate commands to be entered at a terminal. The <code>$</code> represents the prompt, which might be different on your system.</p>"},{"location":"upload/#preparing-example-fastq-files","title":"Preparing example FASTQ files","text":"<p>As an example, let's imagine we want to upload the two example files in Conor Meehan's Pathogen genomics course as part of the mSCAPE project. The two files are from Hikichi et al. (2019), <code>DRR187559_1.fastqsanger.bz2</code> and <code>DRR187559_2.fastqsanger.bz2</code>, available in this Zenodo archive.  You can download the files either by clicking on them in the Zenodo interface or with the common command line tools <code>wget</code>: <pre><code>$ wget https://zenodo.org/record/4534098/files/DRR187559_1.fastqsanger.bz2\n$ wget https://zenodo.org/record/4534098/files/DRR187559_2.fastqsanger.bz2\n</code></pre> or <code>curl</code>: <pre><code>$ curl -L https://zenodo.org/record/4534098/files/DRR187559_1.fastqsanger.bz2 -O\n$ curl -L https://zenodo.org/record/4534098/files/DRR187559_2.fastqsanger.bz2 -O\n</code></pre></p> <p>These two files are bzip2 files, not gzip, which is what we need.  We can convert them by piping the output from <code>bzcat</code> (which decompresses the files) to <code>gzip -c</code> (which compresses the stream and writes it to <code>STDOUT</code>) and then to new files: <pre><code>$ bzcat DRR187559_1.fastqsanger.bz2 | gzip -c &gt; DRR187559_1.fastq.gz\n$ bzcat DRR187559_2.fastqsanger.bz2 | gzip -c &gt; DRR187559_2.fastq.gz\n</code></pre></p> <p>The mSCAPE specification says that our files must have names like <code>mscape.[run_index].[run_id].[extension]</code>, where the extension is <code>1.fastq.gz</code> or <code>2.fastq.gz</code>.  The <code>run_index</code> and <code>run_id</code> can in principle contain any alphanumeric characters, underscores (<code>_</code>) or hyphens ('-'), so you can rename the FASTQ files to whatever meets those requirements. At the command line, this means moving the files with something like: <pre><code>$ mv DRR187559_1.fastq.gz mscape.test-run-index-01.test-run-id-01.1.fastq.gz\n$ mv DRR187559_2.fastq.gz mscape.test-run-index-01.test-run-id-01.2.fastq.gz\n</code></pre></p>"},{"location":"upload/#creating-a-metadata-csv-file","title":"Creating a metadata CSV file","text":"<p>Data uploads require that the FASTQ files are accompanied by a CSV file with the metadata (e.g. when the sample was taken, what type of sample it is). This CSV file must have two rows:</p> <ol> <li>the headers, as in the project metadata specification; and</li> <li>the actual metadata.</li> </ol> <p>It's filename must match the FASTQ files but with the extension <code>csv</code> instead of <code>1.fastq.gz</code> or <code>2.fastq.gz</code> (or <code>fastq.gz</code> if you're trying a single read upload.</p> <p>For the sake of our test and getting to know the system, you should try to create such a file by hand by referring to the relevant metadata spec. The columns are documented in alphabetical order but can be given in any order. The optional columns can be omitted entirely.</p> <p>Note that the <code>run_index</code> and <code>run_id</code> must exactly match the values implied by the FASTQ filenames.  E.g., in my example above</p> <ul> <li>the <code>run_index</code> is <code>test-run-index-01</code> and</li> <li>the <code>run_id</code> is <code>test-run-id-01</code>.</li> </ul> <p>The first few columns of your metadata CSV file might look like <pre><code>run_index,run_id,biosample_id,sample_source,sample_type,...\ntest-run-index-01,test-run-id-01,test-sample-01,nose_and_throat,swab,...\n</code></pre> with no extra spaces separating the fields.</p>"},{"location":"upload/#uploading-files-to-s3-buckets","title":"Uploading files to S3 buckets","text":"<p>You're now ready to upload your data to one of the buckets, which we'll do using the <code>s3cmd</code> tool. There's more information about using <code>s3cmd</code> with Bryn in the CLIMB-BIG-DATA documentation on storage.</p> <p>You can download <code>s3cmd</code> from the <code>s3cmd</code> download pages or install it using <code>pip</code> (perhaps in a virtual or Conda environment) with <pre><code>$ python3 -m pip install s3cmd\n</code></pre> To set <code>s3cmd</code> up to communicate with the buckets, you'll need your API keys from Bryn.  You can find them by logging in to Bryn, selecting the S3 Buckets tab on the left and click the Show API Keys button that appears below the list of buckets.</p> <p>You can then set up <code>s3cmd</code> with <pre><code>$ s3cmd --configure\n</code></pre> When asked for the following, you should give these answers:</p> <ul> <li>Access Key: value of <code>AWS_ACCESS_KEY_ID</code> displayed on Bryn.</li> <li>Secret Key: value of <code>AWS_SECRET_ACCESS_KEY</code> displayed on Bryn.</li> <li>Default Region [US]: leave blank.</li> <li>S3 Endpoint: <code>s3.climb.ac.uk</code></li> <li>DNS-style bucket+hostname:port template for accessing a bucket: <code>%(bucket)s.s3.climb.ac.uk</code></li> </ul> <p>You now should be ready to upload the data.  But where? The names of the S3 buckets for each project are given in the metadata specs but are usually of the form <pre><code>[project]-[sequencing_org]-[platform]-[test_flag]\n</code></pre> We'll use <code>mscape-public-illumina-test</code>, so the command to \"put\" the three files in the bucket would be <pre><code>$ s3cmd put mscape.test-run-index-01.test-run-id-01.csv mscape.test-run-index-01.test-run-id-01.1.fastq.gz mscape.test-run-index-01.test-run-id-01.2.fastq.gz s3://mscape-public-illumina-test\n</code></pre> You should then see the progress of your upload (the files might be split into parts), after which you're back at the terminal.</p> <p>Now what?</p>"},{"location":"upload/#finding-the-result-of-your-upload","title":"Finding the result of your upload","text":"<p>You won't get any feedback from <code>s3cmd</code> about the progress of your data into Onyx.  When the data is received in the bucket, it announces the files to whoever is listening, which includes a program called Roz.  It then starts to check the data: Are all the files present? Are they named correctly?  Is the metadata well-formed?  If so, the data is copied into internal project buckets and a record is added to the database, Onyx.</p> <p>At this point, you can interact with your data through Onyx, which is described in the page on analysing data in Onyx.</p> <p>Last modified 2024-03-25 15:29:15+00:00 (ac20a21)</p>"}]}